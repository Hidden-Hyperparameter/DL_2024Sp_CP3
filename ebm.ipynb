{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f5575f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d6fe6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b66c03c90ce725319f0691dfb29845ac",
     "grade": false,
     "grade_id": "cell-9c430af5d8d383e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Deep Learning Coding Project 3-1: Energy-Based Model\n",
    "\n",
    "Before we start, please put your **Chinese** name and student ID in following format:\n",
    "\n",
    "Name, 0000000000 // e.g.) 傅炜, 2021123123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b760d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e30c80977fd0505d51c0f3fff9f44141",
     "grade": true,
     "grade_id": "name-and-id",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99bd7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46bedcc035ba754f08099a95d00f77f8",
     "grade": false,
     "grade_id": "cell-140b078480df53e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We will use Python 3, [NumPy](https://numpy.org/), and [PyTorch](https://pytorch.org/) packages for implementation. This notebook has been tested under the latest stable release version.\n",
    "\n",
    "In this coding project, you will implement 4 generative models, i.e., energy-based model, flow-based model, variational auto-encoder, and generative adverserial network, to generate MNIST images.\n",
    "\n",
    "**We will implement an energy-based model in this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cd281",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d53ead84771a754bb0c551fa3317688e",
     "grade": false,
     "grade_id": "cell-ffacdab926dcdef6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In some cells and files you will see code blocks that look like this:\n",
    "\n",
    "```Python\n",
    "##############################################################################\n",
    "#                  TODO: You need to complete the code here                  #\n",
    "##############################################################################\n",
    "raise NotImplementedError()\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "```\n",
    "\n",
    "You should replace `raise NotImplementedError()` with your own implementation based on the context, such as:\n",
    "\n",
    "```Python\n",
    "##############################################################################\n",
    "#                  TODO: You need to complete the code here                  #\n",
    "##############################################################################\n",
    "y = w * x + b\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################\n",
    "\n",
    "```\n",
    "\n",
    "When completing the notebook, please adhere to the following rules:\n",
    "\n",
    "+ Do not write or modify any code outside of code blocks\n",
    "+ Do not add or delete any cells from the notebook.\n",
    "+ Run all cells before submission. We will not re-run the entire codebook during grading.\n",
    "\n",
    "**Finally, avoid plagiarism! Any student who violates academic integrity will be seriously dealt with and receive an F for the course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3bbf1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59e39775fb7132b471582e4efedc7243",
     "grade": false,
     "grade_id": "cell-599bd6afccb34d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task\n",
    "\n",
    "The energy-based method aims to train a parameterized model $E = f(x;\\theta)$ to\n",
    "model the unnormalized data distribution $p(x)\\propto \\exp(-E)$. In this notebook, we instantiate\n",
    "$E = f(x;\\theta)$ as an MLP. Your tasks are as follows:\n",
    "\n",
    "1. **Implement all the missing parts in the contrastive-divergence training pipeline.**\n",
    "\n",
    "Basically, we want to decrease\n",
    "the energy of positive samples while increase the energy of negative samples. The positive samples are from the training set, and the negative\n",
    "samples are sampled using Langevin dynamics starting from either random noise or previously generated samples.\n",
    "\n",
    "2. **Implement an inpainting procedure to recover the original image.**\n",
    "\n",
    "We corrupt the images by adding noise to the pixels in even rows (see\n",
    "below). Please implement an inpainting procedure to recover the original\n",
    "image, then report the\n",
    "mean squared difference between your recovered images and the ground\n",
    "truth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8228e39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8faaef554f2902c0d2a24e870f8a80c",
     "grade": false,
     "grade_id": "cell-1c233faf26d419be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# figure size in inches optional\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "\n",
    "# read images\n",
    "img_A = mpimg.imread('./ebm/groundtruth.png')\n",
    "img_B = mpimg.imread('./ebm/corrupted.png')\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img_A)\n",
    "ax[1].imshow(img_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cb6d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84429f7ac1851d0fbe339858358aaf4a",
     "grade": false,
     "grade_id": "cell-53585dd2f2b21500",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Submission\n",
    "\n",
    "You need to submit your code (this notebook), your trained model (named `./ebm/ebm_best.pth`), and your report:\n",
    "\n",
    "+ **Code**\n",
    "\n",
    "Remember to run all the cells before submission. Remain your tuned hyperparameters unchanged.\n",
    "\n",
    "+ **Model**\n",
    "\n",
    "In this notebook, we select the best model according to the MSE of inpainting. You can also manually test your models and select the best one. **Please do not submit any other checkpoints except for `./ebm/ebm_best.pth`!**\n",
    "\n",
    "+ **Report**\n",
    "\n",
    "Please include inpainting examples and the inpainting MSE on validation set in your\n",
    "report. Note that you only need to write a single report for this coding project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa645f3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59d2220da64226d8d0d20aeddc57167c",
     "grade": false,
     "grade_id": "cell-53585dd2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "\n",
    "Your implementation will be graded based on **the mean squared error\n",
    "of inpainting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90a8be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "629c76063b8cf64b9021654fbe717d41",
     "grade": false,
     "grade_id": "cell-527c7725f3508ba0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tips\n",
    "\n",
    "+ Training with naive contrastive-divergence algorithm will make your model diverge quickly (think about why). Therefore, you need to add a L2 regularization term $\\alpha(E_\\theta(x+)^2 + E_\\theta(x-)^2)$ to stabilize training.\n",
    "\n",
    "+ Keep track of the generated samples during training to get a sense of how well your model is evolving.\n",
    "\n",
    "+ You can take a look at the paper [Implicit Generation and Generalization in Energy Based Models](https://arxiv.org/pdf/1903.08689.pdf) to learn more about useful tricks to get your model working.\n",
    "\n",
    "+ Make sure your code runs fine with the evaluation cell in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd040c70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54854fcdc1556d353b55bc4d1a133674",
     "grade": false,
     "grade_id": "cell-2b4bea3e44a7b81b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Set Up Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca3738",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb447e0084709f0b673b1e91ba0aa1a",
     "grade": false,
     "grade_id": "cell-291232b1c59e4f02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you use Colab in this coding project, please uncomment the code, fill the `GOOGLE_DRIVE_PATH_AFTER_MYDRIVE` and run the following cells to mount your Google drive. Then, the notebook can find the required file (i.e., utils.py). If you run the notebook locally, you can skip the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2354b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34bc8b23f9c8e480a9671ef3453e7ac",
     "grade": false,
     "grade_id": "cell-a551fcc5ff27fb87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd2080",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d5d6f96e1d7ce5df1315172b57173de",
     "grade": false,
     "grade_id": "cell-e11eaf041d72deda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from utils import hello\n",
    "hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89801ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c559f41bf7c84970b94a49b43e138e98",
     "grade": false,
     "grade_id": "cell-ab2926992ebc021c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, please run the following cell to import some base classes for implementation (no matter whether you use colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1d5cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6d9d087b7f8aedc3401222f717bb07",
     "grade": false,
     "grade_id": "cell-c0b91f0d2b7ecc80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from utils import save_model, load_model, corruption, train_set, val_set\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "os.makedirs('./ebm', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b76802",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbb5921ccbc0e1e14fd40df09afebcac",
     "grade": false,
     "grade_id": "cell-f28aaf301b501410",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## MLP Model\n",
    "\n",
    "We have provided an example MLP implementation. Feel free to modify the following cell the implement your own model.\n",
    "\n",
    "**Note that your model should be an MLP!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBackbone(nn.Module):\n",
    "    # feel free to modify this\n",
    "    def __init__(self, input_shape, hidden_size, activation=nn.functional.elu):\n",
    "        super(MlpBackbone, self).__init__()\n",
    "        self.input_shape = input_shape  # (C, H, W)\n",
    "        self.hidden_size = hidden_size\n",
    "        # Layers\n",
    "        self.fc1 = nn.Linear(np.prod(self.input_shape), self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc4 = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        out = self.fc4(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d61159f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd456d1555c954ff15d4cfcb44b144f5",
     "grade": false,
     "grade_id": "cell-cafb02a0cc941c58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Sampling\n",
    "\n",
    "Implement Langevin dynamics in the following cell. Pay attention to the gradients of both your energy model and input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704099a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d2744d6a964f70ff2c85c161f92c9f",
     "grade": false,
     "grade_id": "cell-afd44e44fcd9d650",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def langevin_step(energy_model, x, step_lr, eps, max_grad_norm):\n",
    "    \"\"\"\n",
    "    Perform one step of Langevin dynamics sampling.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used for sampling.\n",
    "        x (torch.Tensor): The input tensor to update via Langevin dynamics.\n",
    "        step_lr (float): The learning rate of the optimizer used to update the input.\n",
    "        eps (float): The step size of the Langevin dynamics update.\n",
    "        max_grad_norm (float or None): The maximum norm of the gradient for gradient clipping.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The updated input tensor after one step of Langevin dynamics.\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    #                  TODO: You need to complete the code here                  #\n",
    "    ##############################################################################\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1fdbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5171faedb56d4b5f97620596006e4525",
     "grade": false,
     "grade_id": "cell-508a10378fa57a85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Inpainting\n",
    "\n",
    "Implement the inpainting procedure. Think about the difference between sampling and inpainting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed1856",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15d3e13b437efa0e295540e214b3a612",
     "grade": false,
     "grade_id": "cell-5fce3238f7ff50db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def inpainting(energy_model, x, mask, n_steps, step_lr, max_grad_norm):\n",
    "    \"\"\"\n",
    "    Inpainting function that completes an image given a masked input using Langevin dynamics.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used to generate the image.\n",
    "        x (torch.Tensor): The input tensor, a masked image that needs to be completed.\n",
    "        mask (torch.Tensor): The mask tensor, with the same shape as x, where 1 indicates the corresponding\n",
    "                             pixel is visible and 0 indicates it is missing.\n",
    "        n_steps (int): The number of steps of Langevin dynamics to run.\n",
    "        step_lr (float): The step size of Langevin dynamics.\n",
    "        max_grad_norm (float or None): The maximum gradient norm to be used for gradient clipping. If None, \n",
    "                                       no gradient clipping is performed.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The completed image tensor.\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    #                  TODO: You need to complete the code here                  #\n",
    "    ##############################################################################\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bd650",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6153ff029424a3266efd4b44329a1223",
     "grade": false,
     "grade_id": "cell-e4f7157f3a2421d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(energy_model, val_loader, n_sample_steps, step_lr, langevin_grad_norm, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluates the energy model on the validation set and returns the corruption MSE,\n",
    "    recovered MSE, corrupted images, and recovered images for visualization.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): Trained energy-based model.\n",
    "        val_loader (torch.utils.data.DataLoader): Validation data loader.\n",
    "        n_sample_steps (int): Number of Langevin dynamics steps to take when sampling.\n",
    "        step_lr (float): Learning rate to use during Langevin dynamics.\n",
    "        langevin_grad_norm (float): Maximum L2 norm of the Langevin dynamics gradient.\n",
    "        device (str): Device to use (default='cuda').\n",
    "    \"\"\"\n",
    "    mse = corruption_mse = 0\n",
    "    energy_before_sampling = energy_after_sampling = 0\n",
    "    n_batches = 0\n",
    "    energy_model.eval()\n",
    "\n",
    "    pbar = tqdm(total=len(val_loader.dataset))\n",
    "    pbar.set_description('Eval')\n",
    "    for data, _ in val_loader:\n",
    "        n_batches += data.shape[0]\n",
    "        data = data.to(device)\n",
    "        broken_data, mask = corruption(data, type_='ebm')\n",
    "        energy_before_sampling += energy_model(broken_data).sum().item()\n",
    "        recovered_img = inpainting(energy_model, broken_data, mask,\n",
    "                                   n_sample_steps, step_lr, langevin_grad_norm)\n",
    "        energy_after_sampling += energy_model(recovered_img).sum().item()\n",
    "\n",
    "        mse += np.mean((data.detach().cpu().numpy().reshape(-1, 28 * 28) - recovered_img.detach().cpu().numpy().reshape(-1, 28 * 28)) ** 2, -1).sum().item()\n",
    "        corruption_mse += np.mean((data.detach().cpu().numpy().reshape(-1, 28 * 28) - broken_data.detach().cpu().numpy().reshape(-1, 28 * 28)) ** 2, -1).sum().item()\n",
    "\n",
    "        pbar.update(data.shape[0])\n",
    "        pbar.set_description('Corruption MSE: {:.6f}, Recovered MSE: {:.6f}, Energy Before Sampling: {:.6f}, Energy After Sampling: {:.6f}'.format(\n",
    "            corruption_mse / n_batches, mse / n_batches, energy_before_sampling / n_batches, energy_after_sampling / n_batches))\n",
    "\n",
    "    pbar.close()\n",
    "    return (corruption_mse / n_batches, mse / n_batches, data[:100].detach().cpu(), broken_data[:100].detach().cpu(), recovered_img[:100].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62fbcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "408288173fbc37fcc2d75c0057690de4",
     "grade": false,
     "grade_id": "cell-bfaee9e8110d2da5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training\n",
    "Fill the missing parts in the `train` function. There are some comments implying what to do in the corresponding blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bdcb85",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53e89f05699b12aa2cb1748b4e0b43b7",
     "grade": false,
     "grade_id": "cell-e72fcecf0e87cf84",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, energy_model, train_loader, val_loader, optimizer, n_sample_steps, step_lr, langevin_eps, langevin_grad_norm, l2_alpha,\n",
    "          device='cuda', buffer_maxsize=int(1e4), replay_ratio=0.95, save_interval=1):\n",
    "    energy_model.to(device)\n",
    "    replay_buffer = torch.zeros(buffer_maxsize, 1, 28, 28)\n",
    "    buffer_size = buffer_ptr = 0\n",
    "    best_mse = np.inf\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = energy_before = energy_plus = energy_minus = n_batches = 0\n",
    "        pbar = tqdm(total=len(train_loader.dataset))\n",
    "        pbar.set_description('Train')\n",
    "        for i, (x_plus, _) in enumerate(train_loader):\n",
    "            n_batches += x_plus.shape[0]\n",
    "            bs = x_plus.shape[0]\n",
    "\n",
    "            # init negative samples\n",
    "            if buffer_size == 0:\n",
    "                x_minus = torch.rand_like(x_plus)\n",
    "            else:\n",
    "                ##############################################################################\n",
    "                #                  TODO: You need to complete the code here                  #\n",
    "                ##############################################################################\n",
    "                # YOUR CODE HERE\n",
    "                raise NotImplementedError()\n",
    "                ##############################################################################\n",
    "                #                              END OF YOUR CODE                              #\n",
    "                ##############################################################################\n",
    "            x_minus = x_minus.to(device)\n",
    "\n",
    "            energy_before += energy_model(x_minus).sum().item()\n",
    "\n",
    "            # sample negative samples\n",
    "            ##############################################################################\n",
    "            #                  TODO: You need to complete the code here                  #\n",
    "            ##############################################################################\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            ##############################################################################\n",
    "            #                              END OF YOUR CODE                              #\n",
    "            ##############################################################################\n",
    "\n",
    "            # extend buffer\n",
    "            if buffer_ptr + bs <= buffer_maxsize:\n",
    "                replay_buffer[buffer_ptr: buffer_ptr +\n",
    "                              bs] = ((x_minus * 255).to(torch.uint8).float() / 255).cpu()\n",
    "            else:\n",
    "                x_minus_ = (\n",
    "                    (x_minus * 255).to(torch.uint8).float() / 255).cpu()\n",
    "                replay_buffer[buffer_ptr:] = x_minus_[\n",
    "                    :buffer_maxsize - buffer_ptr]\n",
    "                remaining = bs - (buffer_maxsize - buffer_ptr)\n",
    "                replay_buffer[:remaining] = x_minus_[\n",
    "                    buffer_maxsize - buffer_ptr:]\n",
    "            buffer_ptr = (buffer_ptr + bs) % buffer_maxsize\n",
    "            buffer_size = min(buffer_maxsize, buffer_size + bs)\n",
    "\n",
    "            # compute loss\n",
    "            energy_model.train()\n",
    "            x_plus = x_plus.to(device)\n",
    "            x_minus = x_minus.to(device)\n",
    "            e_plus = energy_model(x_plus)\n",
    "            e_minus = energy_model(x_minus)\n",
    "            ##############################################################################\n",
    "            #                  TODO: You need to complete the code here                  #\n",
    "            ##############################################################################\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            ##############################################################################\n",
    "            #                              END OF YOUR CODE                              #\n",
    "            ##############################################################################\n",
    "\n",
    "            train_loss += loss.sum().item()\n",
    "            energy_plus += e_plus.sum().item()\n",
    "            energy_minus += e_minus.sum().item()\n",
    "\n",
    "            pbar.update(x_plus.size(0))\n",
    "            pbar.set_description(\"Train Epoch {}, Train Loss: {:.6f}, \".format(epoch + 1, train_loss / n_batches) +\n",
    "                                 \"Energy Before Sampling: {:.6f}, \".format(energy_before / n_batches) +\n",
    "                                 \"Energy After Sampling: {:.6f}, \".format(energy_minus / n_batches) +\n",
    "                                 \"Energy of Ground Truth: {:.6f}\".format(energy_plus / n_batches))\n",
    "        pbar.close()\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            os.makedirs(f'./ebm/{epoch + 1}', exist_ok=True)\n",
    "            energy_model.eval()\n",
    "            save_model(f'./ebm/{epoch + 1}/ebm.pth',\n",
    "                       energy_model, optimizer, replay_buffer)\n",
    "\n",
    "            # evaluate inpaiting\n",
    "            # feel free to change the inpainting parameters!\n",
    "            c_mse, r_mse, original, broken, recovered = evaluate(energy_model, val_loader,\n",
    "                                                                 100, 1, 0.03, device=device)\n",
    "            torchvision.utils.save_image(\n",
    "                original, f\"./ebm/{epoch + 1}/groundtruth.png\", nrow=10)\n",
    "            torchvision.utils.save_image(\n",
    "                broken, f\"./ebm/{epoch + 1}/corrupted.png\", nrow=10)\n",
    "            torchvision.utils.save_image(\n",
    "                recovered, f\"./ebm/{epoch + 1}/recovered.png\", nrow=10)\n",
    "            if r_mse < best_mse:\n",
    "                print(f'Current best MSE: {best_mse} -> {r_mse}')\n",
    "                best_mse = r_mse\n",
    "                save_model('./ebm/ebm_best.pth', energy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334975fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MlpBackbone((1, 28, 28), 1024).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.0, 0.999))\n",
    "\n",
    "train_loader = DataLoader(train_set, 256, shuffle=True, drop_last=False, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, 500, shuffle=True, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150ba25",
   "metadata": {},
   "source": [
    "Now you can start your training. Please keep in mind that this cell may **NOT** be run when we evaluate your assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free the change training hyper-parameters!\n",
    "train(20, model, train_loader, val_loader, optimizer, 60, 1, 0.005, 0.03, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d9ad1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "346cba624d53af3f3fed53aab993f261",
     "grade": false,
     "grade_id": "cell-c20c624e7ec0d633",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Make sure you can run the following evaluation cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change evaluation parameters!\n",
    "# inpainting parameters are not necessarily the same as sampling parameters\n",
    "n_sample_steps = 100\n",
    "step_lr = 1\n",
    "langevin_grad_norm = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fa737",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a52957140b64eb164a8f5bc3ecee0a5c",
     "grade": false,
     "grade_id": "cell-a3504d53a9a04b33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(load_model('./ebm/ebm_best.pth')[0])\n",
    "corruption_mse, mse, _, _, _ = evaluate(model, val_loader, n_sample_steps, step_lr, langevin_grad_norm, device=device)\n",
    "print(f'Corruption MSE: {corruption_mse}')\n",
    "print(f'Recovered MSE: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
